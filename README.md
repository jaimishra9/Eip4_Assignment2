WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

Train on 60000 samples, validate on 10000 samples
Epoch 1/20

Epoch 00001: LearningRateScheduler setting learning rate to 0.003.
60000/60000 [==============================] - 11s 183us/step - loss: 0.2291 - acc: 0.9270 - val_loss: 0.0749 - val_acc: 0.9759
Epoch 2/20

Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.
60000/60000 [==============================] - 6s 101us/step - loss: 0.0675 - acc: 0.9785 - val_loss: 0.0625 - val_acc: 0.9798
Epoch 3/20

Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.
60000/60000 [==============================] - 6s 102us/step - loss: 0.0488 - acc: 0.9845 - val_loss: 0.0374 - val_acc: 0.9879
Epoch 4/20

Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.
60000/60000 [==============================] - 6s 100us/step - loss: 0.0407 - acc: 0.9870 - val_loss: 0.0429 - val_acc: 0.9871
Epoch 5/20

Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.
60000/60000 [==============================] - 6s 100us/step - loss: 0.0367 - acc: 0.9882 - val_loss: 0.0309 - val_acc: 0.9899
Epoch 6/20

Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.
60000/60000 [==============================] - 6s 100us/step - loss: 0.0324 - acc: 0.9900 - val_loss: 0.0257 - val_acc: 0.9921
Epoch 7/20

Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.
60000/60000 [==============================] - 6s 100us/step - loss: 0.0295 - acc: 0.9905 - val_loss: 0.0252 - val_acc: 0.9911
Epoch 8/20

Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.
60000/60000 [==============================] - 6s 101us/step - loss: 0.0288 - acc: 0.9908 - val_loss: 0.0246 - val_acc: 0.9922
Epoch 9/20

Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.
60000/60000 [==============================] - 6s 102us/step - loss: 0.0273 - acc: 0.9913 - val_loss: 0.0264 - val_acc: 0.9915
Epoch 10/20

Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.
60000/60000 [==============================] - 6s 104us/step - loss: 0.0249 - acc: 0.9916 - val_loss: 0.0266 - val_acc: 0.9912
Epoch 11/20

Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.
60000/60000 [==============================] - 6s 104us/step - loss: 0.0243 - acc: 0.9919 - val_loss: 0.0251 - val_acc: 0.9921
Epoch 12/20

Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.
60000/60000 [==============================] - 6s 102us/step - loss: 0.0215 - acc: 0.9929 - val_loss: 0.0281 - val_acc: 0.9920
Epoch 13/20

Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.
60000/60000 [==============================] - 6s 102us/step - loss: 0.0210 - acc: 0.9932 - val_loss: 0.0237 - val_acc: 0.9927
Epoch 14/20

Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.
60000/60000 [==============================] - 6s 100us/step - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0227 - val_acc: 0.9932
Epoch 15/20

Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.
60000/60000 [==============================] - 6s 99us/step - loss: 0.0191 - acc: 0.9937 - val_loss: 0.0232 - val_acc: 0.9927
Epoch 16/20

Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.
60000/60000 [==============================] - 6s 100us/step - loss: 0.0183 - acc: 0.9942 - val_loss: 0.0209 - val_acc: 0.9937
Epoch 17/20

Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.
60000/60000 [==============================] - 6s 101us/step - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0209 - val_acc: 0.9941
Epoch 18/20

Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.
60000/60000 [==============================] - 6s 101us/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0218 - val_acc: 0.9940
Epoch 19/20

Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.
60000/60000 [==============================] - 6s 100us/step - loss: 0.0168 - acc: 0.9945 - val_loss: 0.0215 - val_acc: 0.9934
Epoch 20/20

Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.
60000/60000 [==============================] - 6s 100us/step - loss: 0.0176 - acc: 0.9942 - val_loss: 0.0210 - val_acc: 0.9934
<keras.callbacks.History at 0x7f2dbc0b7c50>
