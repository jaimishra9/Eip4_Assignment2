WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

Train on 60000 samples, validate on 10000 samples
Epoch 1/20

Epoch 00001: LearningRateScheduler setting learning rate to 0.003.
60000/60000 [==============================] - 15s 245us/step - loss: 0.2126 - acc: 0.9329 - val_loss: 0.0556 - val_acc: 0.9830
Epoch 2/20

Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.
60000/60000 [==============================] - 9s 156us/step - loss: 0.0644 - acc: 0.9798 - val_loss: 0.0532 - val_acc: 0.9833
Epoch 3/20

Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.
60000/60000 [==============================] - 9s 155us/step - loss: 0.0503 - acc: 0.9846 - val_loss: 0.0350 - val_acc: 0.9891
Epoch 4/20

Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.
60000/60000 [==============================] - 9s 155us/step - loss: 0.0414 - acc: 0.9871 - val_loss: 0.0372 - val_acc: 0.9886
Epoch 5/20

Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.
60000/60000 [==============================] - 9s 156us/step - loss: 0.0384 - acc: 0.9879 - val_loss: 0.0305 - val_acc: 0.9895
Epoch 6/20

Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.
60000/60000 [==============================] - 9s 155us/step - loss: 0.0350 - acc: 0.9891 - val_loss: 0.0231 - val_acc: 0.9935
Epoch 7/20

Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.
60000/60000 [==============================] - 9s 156us/step - loss: 0.0304 - acc: 0.9900 - val_loss: 0.0242 - val_acc: 0.9926
Epoch 8/20

Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.
60000/60000 [==============================] - 9s 156us/step - loss: 0.0280 - acc: 0.9916 - val_loss: 0.0254 - val_acc: 0.9921
Epoch 9/20

Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.
60000/60000 [==============================] - 9s 155us/step - loss: 0.0271 - acc: 0.9910 - val_loss: 0.0256 - val_acc: 0.9917
Epoch 10/20

Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.
60000/60000 [==============================] - 9s 155us/step - loss: 0.0253 - acc: 0.9916 - val_loss: 0.0232 - val_acc: 0.9927
Epoch 11/20

Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.
60000/60000 [==============================] - 9s 156us/step - loss: 0.0246 - acc: 0.9918 - val_loss: 0.0216 - val_acc: 0.9935
Epoch 12/20

Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.
60000/60000 [==============================] - 9s 157us/step - loss: 0.0222 - acc: 0.9928 - val_loss: 0.0222 - val_acc: 0.9932
Epoch 13/20

Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.
60000/60000 [==============================] - 9s 155us/step - loss: 0.0229 - acc: 0.9920 - val_loss: 0.0219 - val_acc: 0.9933
Epoch 14/20

Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.
60000/60000 [==============================] - 9s 156us/step - loss: 0.0206 - acc: 0.9930 - val_loss: 0.0205 - val_acc: 0.9936
Epoch 15/20

Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.
60000/60000 [==============================] - 9s 156us/step - loss: 0.0199 - acc: 0.9932 - val_loss: 0.0212 - val_acc: 0.9930
Epoch 16/20

Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.
60000/60000 [==============================] - 9s 154us/step - loss: 0.0197 - acc: 0.9935 - val_loss: 0.0236 - val_acc: 0.9932
Epoch 17/20

Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.
60000/60000 [==============================] - 9s 156us/step - loss: 0.0185 - acc: 0.9939 - val_loss: 0.0214 - val_acc: 0.9935
Epoch 18/20

Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.
60000/60000 [==============================] - 10s 159us/step - loss: 0.0191 - acc: 0.9936 - val_loss: 0.0192 - val_acc: 0.9940
Epoch 19/20

Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.
60000/60000 [==============================] - 9s 156us/step - loss: 0.0170 - acc: 0.9944 - val_loss: 0.0217 - val_acc: 0.9932
Epoch 20/20

Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.
60000/60000 [==============================] - 9s 155us/step - loss: 0.0176 - acc: 0.9945 - val_loss: 0.0237 - val_acc: 0.9922
<keras.callbacks.History at 0x7fa173faea90>
